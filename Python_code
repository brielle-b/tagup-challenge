import numpy as np
import pandas as pd
import boto3
import sqlite3
import xarray as xr
import matplotlib.pyplot as plt
con = sqlite3.connect("/Users/briellebalswick/Downloads/exampleco_db.db")
cur = con.cursor()
# investigate trend over 4 different sensors
feat_0 = pd.read_sql_query("SELECT * from feat_0", con)#.groupby(["machine"]).mean()
#print(feat_0)
feat_1=pd.read_sql_query("SELECT * from feat_1", con)#.groupby(["machine"]).mean()
#print(feat_1)
feat_2=pd.read_sql_query("SELECT * from feat_2", con)#.groupby(["machine"]).mean()
#print(feat_2)
feat_3=pd.read_sql_query("SELECT * from feat_3", con)#.groupby(["machine"]).mean()
#print(feat_3)

# intial array of feat tables
equipment = xr.DataArray(np.array([feat_0,feat_1,feat_2,feat_3]),dims=("feat","rows","cols"))


# analyze by feat table first and see note any distinct difference between tables
for i in range(4):
    plt.scatter(equipment[i,:,1],equipment[i,:,2])
    plt.title("feat "+str(i))
    plt.xticks(rotation=45)
    plt.show()
    stats=pd.Series(equipment[i,:,2]).describe()
    print("feat",str(i), ": ",stats)
    # no particular pattern by table with all machines together

# add static data to tables with sensor data
static= pd.read_sql_query("SELECT * FROM static_data",con)
complete_data= pd.concat([feat_0,feat_1,feat_2,feat_3])
install_date=dict(zip(list(static["machine_id"]),list(static["install_date"])))
Model=dict(zip(list(static["machine_id"]),list(static["model"])))
room=dict(zip(list(static["machine_id"]),list(static["room"])))
complete_data["install_date"] = complete_data["machine"].map(install_date)
complete_data["model"] = complete_data["machine"].map(Model)
complete_data["room"] = complete_data["machine"].map(room)

# plot all data and look at spread
plt.boxplot(complete_data.value)
plt.title("Overall spread across all feat tables")
plt.show()
# filter out the faulty group sensors, just focus on group around 0, cutoff is clear around at least (-200,200)
non_faulty= complete_data[(complete_data.value<200) & (complete_data.value>-200)]
print(len(non_faulty))
plt.boxplot(non_faulty.value)
plt.title("Faulty sensored groups removed")
plt.show()
new_arr= xr.DataArray(np.array(complete_data),  dims=("rows","cols"))

plt.scatter(non_faulty.machine,non_faulty.value)
plt.xticks(rotation=45)
plt.title("Values across machines")
plt.show()
# look at overall statistics for each machine
print(non_faulty.groupby(["machine"]).describe())
# create another array with only values around zero
new_arr= xr.DataArray(np.array(non_faulty), dims=("rows","columns"))
grouped =non_faulty.groupby(["machine","timestamp"]).describe()
print(grouped)
# get machine numbers for grouping
machines= list(static["machine_id"])
by_machine=[]
# create array of machine info separated for each machine
for i in range(20):
    by_machine.append(non_faulty[non_faulty.machine==machines[i]])

# remove outliers for each machine
final_arr=[]
for i in range(20):
    MEAN = by_machine[i].value.mean()
    STDEV= by_machine[i].value.std()
    lower_bound = MEAN - (STDEV * 2)
    upper_bound = MEAN + (STDEV * 2)
    no_outliers = [True if x < upper_bound and x > lower_bound else False for x in by_machine[i].value]
    # show spread for each machine
    plt.boxplot(by_machine[i][no_outliers].value)
    plt.title(machines[i])
    plt.show()
    print(by_machine[i][no_outliers].describe())
    final_arr.append(np.array(by_machine[i][no_outliers]))
    # summarize new stats
# final array of machine arrays for a total of 20
final_arr =np.array(final_arr)
print(final_arr)
print(final_arr.shape)

# next step would be to send to the s3 bucket which I would have done using boto library
'''
 # it would look something like this but I currently cannot access my aws account to verify
session = boto3.Session(
aws_access_key_id='<your_access_key_id>',
aws_secret_access_key='<your_secret_access_key>'
)
#Creating S3 Resource From the Session.
s3 = session.resource('s3')
object = s3.Object('<bucket_name>', 'final_text.txt')
result = object.put(Body=str(final_arr))
'''
